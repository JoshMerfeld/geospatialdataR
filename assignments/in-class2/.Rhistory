wrapper <- function(i){
grid$weights <- weights[i,]
# if ((grid$id[i] %in% unique(roads$id))==FALSE){
#   return(NA)
#   next
# }
temp <- roads |>
left_join(as_tibble(grid) |> dplyr::select(id, weights), by = "id")
reg1 <- fepois(events_riot ~ log(length + 1) + log(lengthbuffer50new + 1)*max50 + log(pop) + log(popbuffer50donut + popbuffer25donut + popbuffer10donut) | id + year,
data = temp, weights = ~weights)
return(coeftable(reg1)[6,1])
}
results <- pbmclapply(1:nrow(grid), wrapper, mc.cores = 10)
results <- unlist(results)
grid$coef2 <- results
ggplot() +
geom_spatvector(data = grid, aes(fill = coef2), color = NA) +
scale_fill_distiller("Coefficient:", palette = "Spectral") +
theme_bw()
# if ((grid$id[i] %in% unique(roads$id))==FALSE){
#   return(NA)
#   next
# }
temp <- roads |>
left_join(as_tibble(grid) |> dplyr::select(id, weights), by = "id")
reg1 <- fepois(events_riot ~ log(length + 1) + log(lengthbuffer50new + 1)*max50 + log(pop) + log(popbuffer50donut + popbuffer25donut + popbuffer10donut) | id + year,
data = temp, weights = ~weights)
reg1
reg1 <- fepois(events_riot ~ log(length + 1) + log(lengthbuffer50new + 1)*max50 + log(pop) + log(popbuffer50donut + popbuffer25donut + popbuffer10donut) | id + year,
data = temp, weights = ~weights)
reg1
coeftable(reg1)
grid
# create kernels (can choose traingular or epanechnikov)
kernelfun <- function(x, bw = 250, k = "epanechnikov"){
if (k=="epanechnikov"){ # this calculates the epanechnikov kernel (but with max of one)
w <- ifelse(x>bw, 0, (1 - (x/bw)^2))
} else{
w <- ifelse(x>bw, 0, (1 - (x/bw))) # triangular kernel
}
return(w)
}
weights <- apply(dist, 1, kernelfun)
wrapper <- function(i){
grid$weights <- weights[i,]
# if ((grid$id[i] %in% unique(roads$id))==FALSE){
#   return(NA)
#   next
# }
temp <- roads |>
left_join(as_tibble(grid) |> dplyr::select(id, weights), by = "id")
reg1 <- fepois(events_all ~ log(length + 1) + log(lengthbuffer50new + 1) + log(pop) + log(popbuffer50donut + popbuffer25donut + popbuffer10donut) | id + year,
data = temp, weights = ~weights)
return(coeftable(reg1)[2,1])
}
results <- pbmclapply(1:nrow(grid), wrapper, mc.cores = 10)
results <- unlist(results)
grid$coef <- results
results
grepl("Error", results)
# if error -> NA
results[grepl("Error", results)] <- ""
results
results <- as.numeric(results)
results
grid$coef <- results
ggplot() +
geom_spatvector(data = grid, aes(fill = coef), color = NA) +
scale_fill_distiller("Coefficient:", palette = "Spectral", na.value = NA) +
theme_bw()
summary(grid$coef)
grid$coef <- ifelse(grid$coef>quantile(grid$coef, 0.95), quantile(grid$coef, 0.95), grid$coef)
grid$coef <- ifelse(grid$coef<quantile(grid$coef, 0.05), quantile(grid$coef, 0.05), grid$coef)
grid$coef <- ifelse(grid$coef>quantile(grid$coef, 0.99, na.rm = TRUE), quantile(grid$coef, 0.99, na.rm = TRUE), grid$coef)
grid$coef <- ifelse(grid$coef<quantile(grid$coef, 0.01, na.rm = TRUE), quantile(grid$coef, 0.01, na.rm = TRUE), grid$coef)
ggplot() +
geom_spatvector(data = grid, aes(fill = coef), color = NA) +
scale_fill_distiller("Coefficient:", palette = "Spectral", na.value = NA) +
theme_bw()
# create kernels (can choose traingular or epanechnikov)
kernelfun <- function(x, bw = 250, k = "triangular"){
if (k=="epanechnikov"){ # this calculates the epanechnikov kernel (but with max of one)
w <- ifelse(x>bw, 0, (1 - (x/bw)^2))
} else{
w <- ifelse(x>bw, 0, (1 - (x/bw))) # triangular kernel
}
return(w)
}
weights <- apply(dist, 1, kernelfun)
summary(dist)
max(dist)
# create kernels (can choose traingular or epanechnikov)
kernelfun <- function(x, bw = 500, k = "triangular"){
if (k=="epanechnikov"){ # this calculates the epanechnikov kernel (but with max of one)
w <- ifelse(x>bw, 0, (1 - (x/bw)^2))
} else{
w <- ifelse(x>bw, 0, (1 - (x/bw))) # triangular kernel
}
return(w)
}
weights <- apply(dist, 1, kernelfun)
wrapper <- function(i){
grid$weights <- weights[i,]
# if ((grid$id[i] %in% unique(roads$id))==FALSE){
#   return(NA)
#   next
# }
temp <- roads |>
left_join(as_tibble(grid) |> dplyr::select(id, weights), by = "id")
reg1 <- fepois(events_all ~ log(length + 1) + log(lengthbuffer50new + 1) + log(pop) + log(popbuffer50donut + popbuffer25donut + popbuffer10donut) | id + year,
data = temp, weights = ~weights)
return(coeftable(reg1)[2,1])
}
results <- pbmclapply(1:nrow(grid), wrapper, mc.cores = 10)
results <- unlist(results)
class(results)
is.numeric(results)
# if error -> NA
if (is.numeric(results)==FALSE){
results[grepl("Error", results)] <- ""
results <- as.numeric(results)
}
grid$coef <- results
grid$coef <- ifelse(grid$coef>quantile(grid$coef, 0.99, na.rm = TRUE), quantile(grid$coef, 0.99, na.rm = TRUE), grid$coef)
grid$coef <- ifelse(grid$coef<quantile(grid$coef, 0.01, na.rm = TRUE), quantile(grid$coef, 0.01, na.rm = TRUE), grid$coef)
ggplot() +
geom_spatvector(data = grid, aes(fill = coef), color = NA) +
scale_fill_distiller("Coefficient:", palette = "Spectral", na.value = NA) +
theme_bw()
grid <- grid |>
left_join(roads |> group_by(id) |> summarize(lengthbuffer50new = log(mean(lengthbuffer50new, na.rm = TRUE))) |> ungroup(), by = "id")
grid
summary(grid)
grid <- grid |> dplyr::select(-lengthbuffer50new)
grid <- grid |>
left_join(roads |> group_by(id) |> summarize(lengthbuffer50new = mean(lengthbuffer50new, na.rm = TRUE)) |> ungroup(), by = "id")
grid
summary(grid)
ggplot() +
geom_point(data = grid, aes(x = log(lengthbuffer50new), y = coef)) +
theme_bw()
roads <- roads |>
left_join(as_tibble(grid) |> dplyr::select(id, coef), by = "id")
ggplot() +
geom_point(data = roads, aes(x = log(lengthbuffer50new), y = coef, color = as.factor(year))) +
scale_color_brewer("Year", palette = "RdYlBu") +
theme_bw()
ggplot() +
geom_point(data = roads, aes(x = log(lengthbuffer50new), y = coef, color = as.factor(year)), alpha = 0.5) +
scale_color_brewer("Year", palette = "RdYlBu") +
theme_bw()
ggplot() +
geom_point(data = roads |> mutate(lengthbuffer50new = ifelse(log(lengthbuffer50new)<12, 12, log(lengthbuffer50new))), aes(x = lengthbuffer50new, y = coef, color = as.factor(year)), alpha = 0.5) +
scale_color_brewer("Year", palette = "RdYlBu") +
theme_bw()
# load shapefile
temp <- vect("/Users/Josh/Downloads/MB_2021_AUST_SHP_GDA2020/MB_2021_AUST_GDA2020.shp")
head(temp)
table(temp$STE_NAME21)
library(tidyterra)
# just WA
temp <- temp[temp$STE_NAME21=="Western Australia",]
temp
setwd("~/Dropbox/KDIS/Classes/geospatialdataR/assignments/in-class2")
writeVect(temp, "data/meshblocks.shp")
library(terra)
writeVector(temp, "data/meshblocks.shp")
table(temp$SA3_NAME21)
ggplot() + geom_spatvector(data = temp, aes(fill = SA3_NAME21), color = NA)
# create extent from 30 N to lower extent of temp and from 115 E to 120 E
ext <- extent(115, 120, -30, temp@extent[2])
# create extent from 30 N to lower extent of temp and from 115 E to 120 E
ext <- ext(115, 120, -30, temp@extent[2])
ext(temp)
ext(temp)[[3]]
ext(temp)[3]
# create extent from 30 N to lower extent of temp and from 115 E to 120 E
ext <- ext(115, 120, ext(temp)[3], -30)
ggplot() + geom_spatvector(data = temp, aes(fill = SA3_NAME21), color = NA) + geom_spatvector(data = ext, fill = NA, color = "black")
temp <- crop(temp, ext)
ggplot() + geom_spatvector(data = temp, aes(fill = SA3_NAME21), color = NA)
# create extent from 30 N to lower extent of temp and from 115 E to 120 E
ext <- ext(115, 117, -33, -31)
temp <- crop(temp, ext)
ggplot() + geom_spatvector(data = temp, aes(fill = SA3_NAME21), color = NA)
# create extent from 30 N to lower extent of temp and from 115 E to 120 E
ext <- ext(115.7, 116.5, -32.5, -31.5)
temp <- crop(temp, ext)
ggplot() + geom_spatvector(data = temp, aes(fill = SA3_NAME21), color = NA)
writeVector(temp, "data/meshblocks.shp", overwrite = TRUE)
# pop raster
pop <- rast("/Users/Josh/Downloads/aus_ppp_2020_constrained.tif")
pop <- crop(pop, ext)
ggplot() + geom_spatraster(data = pop)
ggplot() + geom_spatraster(data = log(pop)) + scale_fill_distiller(palette = "Spectral")
# save
writeRaster(pop, "data/pop.tif", overwrite = TRUE)
# load shapefile
temp <- vect("/Users/Josh/Downloads/MB_2021_AUST_SHP_GDA2020/MB_2021_AUST_GDA2020.shp")
temp
# pollution
files <- list.files("/Users/Josh/Dropbox/Papers/auscoal/data/PM/original/WA")
files
stations <- read_csv(files[[1]])
stations <- read_csv(paste0("/Users/Josh/Dropbox/Papers/auscoal/data/PM/original/WA/", files[[1]]))
stations
others <- c()
for (i in files){
# excel files
temp <- read_excel(paste0("/Users/Josh/Dropbox/Papers/auscoal/data/PM/original/WA/", i), sheet = 1)
others <- rbind(others, temp)
}
library(read_excel)
library(readxl)
others <- c()
for (i in files){
# excel files
temp <- read_excel(paste0("/Users/Josh/Dropbox/Papers/auscoal/data/PM/original/WA/", i), sheet = 1)
others <- rbind(others, temp)
}
files[1]
files <- files[-1]
files[1]
for (i in files){
# excel files
temp <- read_excel(paste0("/Users/Josh/Dropbox/Papers/auscoal/data/PM/original/WA/", i), sheet = 1)
others <- rbind(others, temp)
}
others
stations <- read_csv(paste0("/Users/Josh/Dropbox/Papers/auscoal/data/PM/original/WA/", files[[1]]))
# pollution
files <- list.files("/Users/Josh/Dropbox/Papers/auscoal/data/PM/original/WA")
stations <- read_csv(paste0("/Users/Josh/Dropbox/Papers/auscoal/data/PM/original/WA/", files[[1]]))
stations <- stations[,c(2, 3, 4)]
colnames(stations) <- c("site", "latitude", "longitude")
stations$site <- str_to_lower(stations$site)
stations
pollution <- c()
for (i in files){
temp <- read_excel(paste0("/Users/Josh/Dropbox/Papers/auscoal/data/PM/original/WA/", i), sheet = 1)
colnames(temp) <- str_to_lower(colnames(temp))
temp <- temp %>%
select(contains("date"), contains("pm10"), contains("pm25"), contains("station"))
colnames(temp) <- c("date", "pm10", "pm25", "site")
pollution <- rbind(pollution, temp)
}
files <- files[-1]
pollution <- c()
for (i in files){
temp <- read_excel(paste0("/Users/Josh/Dropbox/Papers/auscoal/data/PM/original/WA/", i), sheet = 1)
colnames(temp) <- str_to_lower(colnames(temp))
temp <- temp %>%
select(contains("date"), contains("pm10"), contains("pm25"), contains("station"))
colnames(temp) <- c("date", "pm10", "pm25", "site")
pollution <- rbind(pollution, temp)
}
pollution$site[pollution$site=="Albany Particles A.Q.M.S."] <- "albany"
pollution$site[pollution$site=="Bunbury A.Q.M.S."] <- "bunbury"
pollution$site[pollution$site=="Busselton A.Q.M.S."] <- "busselton"
pollution$site[pollution$site=="Caversham A.Q.M.S."] <- "caversham"
pollution$site[pollution$site=="Collie Particles A.Q.M.S."] <- "collie"
pollution$site[pollution$site=="Duncraig A.Q.M.S."] <- "duncraig"
pollution$site[pollution$site=="Geraldton Particles A.Q.M.S."] <- "geraldton"
pollution$site[pollution$site=="Kalgoorlie A.Q.M.S."] <- "kalgoorlie"
pollution$site[pollution$site=="Quinns Rocks A.Q.M.S."] <- "quinns rocks"
pollution$site[pollution$site=="South Lake A.Q.M.S."] <- "south lake"
pollution$date <- as_date(pollution$date)
# for each day, calculate average for last 7 days
pollution <- pollution %>%
filter(!is.na(date))
dates <- seq(min(pollution$date), max(pollution$date), by = "day")
# make sure all dates are present for each Name
pollution <- pollution %>%
group_by(site) %>%
complete(date = dates) %>%
ungroup()
pollution
pollution <- pollution |>
filter(pm25>=0)
pollution
pollution <- pollution |>
left_join(stations, by = "site")
pollution <- pollution |>
filter(!is.na(lon))
pollution <- pollution |>
filter(!is.na(longitude))
pollution
table(pollution$date)
table(pollution$date[year(pollution$date)>2015])
table(pollution$date[year(pollution$date)>2018])
# seven days (october 1st through 7th, 2019)
pollution <- pollution |>
filter(date >= as_date("2019-10-01") & date <= as_date("2019-10-07"))
pollution
summary(pollution)
pollution <- pollution |>
dplyr::select(-pm10)
pollution
View(pollution)
temp <- vect("data/meshblocks.shp")
# to shape
pollution <- vect(pollution, geom = c("longitude", "latitude"), crs = 4326)
pollution
temp2 <- temp
files <- files[-1]
pollution <- c()
for (i in files){
temp <- read_excel(paste0("/Users/Josh/Dropbox/Papers/auscoal/data/PM/original/WA/", i), sheet = 1)
colnames(temp) <- str_to_lower(colnames(temp))
temp <- temp %>%
select(contains("date"), contains("pm10"), contains("pm25"), contains("station"))
colnames(temp) <- c("date", "pm10", "pm25", "site")
pollution <- rbind(pollution, temp)
}
# some cleaning of names
pollution$site[pollution$site=="Albany Particles A.Q.M.S."] <- "albany"
pollution$site[pollution$site=="Bunbury A.Q.M.S."] <- "bunbury"
pollution$site[pollution$site=="Busselton A.Q.M.S."] <- "busselton"
pollution$site[pollution$site=="Caversham A.Q.M.S."] <- "caversham"
pollution$site[pollution$site=="Collie Particles A.Q.M.S."] <- "collie"
pollution$site[pollution$site=="Duncraig A.Q.M.S."] <- "duncraig"
pollution$site[pollution$site=="Geraldton Particles A.Q.M.S."] <- "geraldton"
pollution$site[pollution$site=="Kalgoorlie A.Q.M.S."] <- "kalgoorlie"
pollution$site[pollution$site=="Quinns Rocks A.Q.M.S."] <- "quinns rocks"
pollution$site[pollution$site=="South Lake A.Q.M.S."] <- "south lake"
pollution$date <- as_date(pollution$date)
# for each day, calculate average for last 7 days
pollution <- pollution %>%
filter(!is.na(date))
dates <- seq(min(pollution$date), max(pollution$date), by = "day")
# make sure all dates are present for each Name
pollution <- pollution %>%
group_by(site) %>%
complete(date = dates) %>%
ungroup()
pollution <- pollution |>
filter(pm25>=0)
pollution <- pollution |>
left_join(stations, by = "site")
pollution <- pollution |>
filter(!is.na(longitude))
# seven days (october 1st through 7th, 2019)
pollution <- pollution |>
filter(date >= as_date("2019-10-01") & date <= as_date("2019-10-07"))
pollution <- pollution |>
dplyr::select(-pm10)
# to shape
pollution <- vect(pollution, geom = c("longitude", "latitude"), "EPSG:4326")
pollution
ggplot() + geom_spatvector(data = temp2) + geom_spatvector(data = pollution, color = "red")
# load shapefile
temp <- vect("/Users/Josh/Downloads/MB_2021_AUST_SHP_GDA2020/MB_2021_AUST_GDA2020.shp")
table(temp$STE_NAME21)
# just WA
temp <- temp[temp$STE_NAME21=="New South Wales",]
ggplot() +
geom_spatvector(temp, fill = NA)
ggplot() +
geom_spatvector(data = temp, fill = NA)
# get locations
locations <- read_csv("/Users/Josh/Dropbox/Papers/auscoal/data/PM/original/NSW/stations_NSW.csv")
# create extent from 30 N to lower extent of temp and from 115 E to 120 E
ext <- ext(151, 153, -34.5, -32)
temp <- crop(temp, ext)
ggplot() +
geom_spatvector(data = temp, fill = NA)
writeVector(temp, "data/meshblocks.shp", overwrite = TRUE)
# create extent from 30 N to lower extent of temp and from 115 E to 120 E
ext <- ext(151, 153, -33.5, -32.5)
temp <- crop(temp, ext)
ggplot() +
geom_spatvector(data = temp, fill = NA)
# load shapefile
temp <- vect("/Users/Josh/Downloads/MB_2021_AUST_SHP_GDA2020/MB_2021_AUST_GDA2020.shp")
# just NSW
temp <- temp[temp$STE_NAME21=="New South Wales",]
ggplot() +
geom_spatvector(data = temp, fill = NA)
# create extent from 30 N to lower extent of temp and from 115 E to 120 E
ext <- ext(150, 152, -33, -34.5)
# create extent from 30 N to lower extent of temp and from 115 E to 120 E
ext <- ext(150, 152, -34.5, -33)
temp <- crop(temp, ext)
ggplot() +
geom_spatvector(data = temp, fill = NA)
writeVector(temp, "data/meshblocks.shp", overwrite = TRUE)
# create extent from 30 N to lower extent of temp and from 115 E to 120 E
ext <- ext(150.5, 151.5, -34.3, -33.2)
temp <- crop(temp, ext)
ggplot() +
geom_spatvector(data = temp, fill = NA)
writeVector(temp, "data/meshblocks.shp", overwrite = TRUE)
pop <- rast("/Users/Josh/Downloads/aus_ppp_2020_constrained.tif")
pop <- crop(pop, ext)
# save
writeRaster(pop, "data/pop.tif", overwrite = TRUE)
# pollution
pollution <- read_xlsx("/Users/Josh/Dropbox/Papers/auscoal/data/PM/original/NSW/daily/nsw-2010-2021.xlsx")
# Wide to long
pollution <- pollution %>%
gather(key = "siteName", value = "value", -Date) %>%
rename(date = Date)
# remove " 24h average [µg/m≥]"
pollution$siteName <- str_remove(pollution$siteName, " 24h average \\[µg/m≥\\]")
pollution$type <- NA
pollution$type[grepl("PM10", pollution$siteName)] <- "pm10"
pollution$type[grepl("PM2.5", pollution$siteName)] <- "pm25"
pollution$siteName <- str_remove(pollution$siteName, " PM10")
pollution$siteName <- str_remove(pollution$siteName, " PM2.5")
# now to wide with pm10 and pm25
pollution <- pollution %>%
spread(key = type, value = value)
pollution$siteName <- str_to_lower(pollution$siteName)
# clean two names
pollution$siteName[pollution$siteName=="albion park sth"] <- "albion park south"
pollution$siteName[pollution$siteName=="wagga wagga nth"] <- "wagga wagga north"
# to day
pollution <- pollution %>%
group_by(siteName, date) %>%
summarize(pm10 = mean(pm10, na.rm = TRUE),
pm25 = mean(pm25, na.rm = TRUE)) %>%
ungroup()
# get locations
locations <- read_csv("/Users/Josh/Dropbox/Papers/auscoal/data/PM/original/NSW/stations_NSW.csv")
locations <- locations %>%
dplyr::select(siteName, latitude = Latitude, longitude = Longitude)
locations$siteName <- str_to_lower(locations$siteName)
# there are some duplicates.
locations <- locations %>%
group_by(siteName) %>%
filter(row_number()==1) %>%
ungroup()
# merge
pollution <- pollution %>%
left_join(locations, by = "siteName")
# fix date
pollution$date <- as.Date(pollution$date, format = "%d/%m/%Y")
# for each day, calculate average for last 7 days
pollution <- pollution %>%
filter(!is.na(date))
pollution
summary(pollution)
# seven days (october 1st through 7th, 2019)
pollution <- pollution |>
filter(date >= as_date("2019-10-01") & date <= as_date("2019-10-07"))
pollution <- pollution |>
dplyr::select(-pm25)
pollution
summary(pollution)
# to shape
pollution <- vect(pollution, geom = c("longitude", "latitude"), "EPSG:4326")
mesh <- vect("data/meshblocks.shp")
ggplot() + geom_spatvector(data = mesh) + geom_spatvector(pollution, color = "red")
ggplot() + geom_spatvector(data = mesh) + geom_spatvector(data = pollution, color = "red")
# pollution
pollution <- read_xlsx("/Users/Josh/Dropbox/Papers/auscoal/data/PM/original/NSW/daily/nsw-2010-2021.xlsx")
# Wide to long
pollution <- pollution %>%
gather(key = "siteName", value = "value", -Date) %>%
rename(date = Date)
# remove " 24h average [µg/m≥]"
pollution$siteName <- str_remove(pollution$siteName, " 24h average \\[µg/m≥\\]")
pollution$type <- NA
pollution$type[grepl("PM10", pollution$siteName)] <- "pm10"
pollution$type[grepl("PM2.5", pollution$siteName)] <- "pm25"
pollution$siteName <- str_remove(pollution$siteName, " PM10")
pollution$siteName <- str_remove(pollution$siteName, " PM2.5")
# now to wide with pm10 and pm25
pollution <- pollution %>%
spread(key = type, value = value)
pollution$siteName <- str_to_lower(pollution$siteName)
# clean two names
pollution$siteName[pollution$siteName=="albion park sth"] <- "albion park south"
pollution$siteName[pollution$siteName=="wagga wagga nth"] <- "wagga wagga north"
# to day
pollution <- pollution %>%
group_by(siteName, date) %>%
summarize(pm10 = mean(pm10, na.rm = TRUE),
pm25 = mean(pm25, na.rm = TRUE)) %>%
ungroup()
# get locations
locations <- read_csv("/Users/Josh/Dropbox/Papers/auscoal/data/PM/original/NSW/stations_NSW.csv")
locations <- locations %>%
dplyr::select(siteName, latitude = Latitude, longitude = Longitude)
locations$siteName <- str_to_lower(locations$siteName)
# there are some duplicates.
locations <- locations %>%
group_by(siteName) %>%
filter(row_number()==1) %>%
ungroup()
# merge
pollution <- pollution %>%
left_join(locations, by = "siteName")
# fix date
pollution$date <- as.Date(pollution$date, format = "%d/%m/%Y")
# for each day, calculate average for last 7 days
pollution <- pollution %>%
filter(!is.na(date))
# seven days (october 1st through 7th, 2019)
pollution <- pollution |>
filter(date >= as_date("2019-10-01") & date <= as_date("2019-10-07"))
pollution <- pollution |>
dplyr::select(-pm25)
# save
write_csv(pollution, "data/pollution.csv")
sa3 <- vect("/Users/Josh/Downloads/SA3_2021_AUST_SHP_GDA2020/SA3_2021_AUST_GDA2020.shp")
sa3
sa3 <- sa3[sa3$STE_NAME21=="New South Wales",]
ggplot() + geom_spatvector(data = sa3)
writeVector(sa3, "data/NSW.shp", overwrite = TRUE)
pollution
length(unique(pollution$siteName))
